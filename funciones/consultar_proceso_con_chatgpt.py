import os
import json
import openai
from difflib import get_close_matches

openai.api_key = os.getenv("OPENAI_API_KEY")

with open("Archivos_estaticos/process_prueba.json", "r", encoding="utf-8") as f:
    PROCESOS = json.load(f)

def consultar_proceso_chatgpt(nombre_proceso: str, atributo_dudado: str) -> str:
    if not nombre_proceso:
        return "‚ùóÔ∏èNo estoy segura a qu√© proceso te refieres. ¬øPodr√≠as especificarlo un poco m√°s?"

    claves_lower = {k.lower(): k for k in PROCESOS}
    coincidencias = get_close_matches(nombre_proceso.lower(), claves_lower.keys(), n=1, cutoff=0.5)
    if not coincidencias:
        return f"‚ùóÔ∏èNo encontr√© ning√∫n proceso que se parezca a '{nombre_proceso}'."

    proceso_clave = claves_lower[coincidencias[0]]
    contenido = PROCESOS[proceso_clave]

    prompt = f"""
Eres Mont Direcci√≥n, una asistente especializada en gesti√≥n de salones de belleza. 
Una usuaria del equipo te ha preguntado sobre el proceso **{proceso_clave}**, espec√≠ficamente sobre: **{atributo_dudado}**.

A continuaci√≥n tienes el contenido completo del procedimiento:
\"\"\"
{contenido}
\"\"\"

Usando esta informaci√≥n, responde de forma clara, profesional y pr√°ctica solo con lo que aparece en el texto. 
No inventes datos que no est√©n presentes. S√© directa y cercana.

Respuesta:
"""

    # üß† Aqu√≠ van los logs que quieres
    print("üß† Procesando proceso:", proceso_clave)
    print("üìÑ Prompt enviado a ChatGPT:\n", prompt)

    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.5
        )
        return response["choices"][0]["message"]["content"].strip()
    except Exception as e:
        return f"‚ùå Error al consultar GPT: {e}"



