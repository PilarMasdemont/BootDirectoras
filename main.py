import os
import json
import logging
from fastapi import FastAPI, Request, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv
from openai import OpenAI

from funciones.explicar_ratio_diario import explicar_ratio_diario

# ‚Äî‚Äî‚Äî‚Äî‚Äî Configuraci√≥n de logging ‚Äî‚Äî‚Äî‚Äî‚Äî
logging.basicConfig(
    level=logging.DEBUG,
    format="%(asctime)s %(levelname)s %(name)s | %(message)s",
)
logger = logging.getLogger("bootdirectoras")

# Carga de la clave
load_dotenv()
API_KEY = os.getenv("OPENAI_API_KEY")
if not API_KEY:
    logger.error("OPENAI_API_KEY no est√° configurado en el entorno")
    raise RuntimeError("OPENAI_API_KEY no est√° configurado.")

client = OpenAI(api_key=API_KEY)

function_schema = [
    {
        "name": "explicar_ratio_diario",
        "description": "...",
        "parameters": {
            "type": "object",
            "properties": {
                "codsalon": {"type": "string"},
                "fecha":    {"type": "string"}
            },
            "required": ["codsalon", "fecha"]
        }
    }
]

app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

from fastapi.responses import JSONResponse
from sheets import cargar_hoja

@app.get("/kpis/30dias")
async def kpis_30dias(codsalon: str):
    """
    Devuelve los KPIs de los √∫ltimos 30 d√≠as para un sal√≥n espec√≠fico.
    """
    try:
        df = cargar_hoja("1882861530")  # GID de la hoja "KPIs_30Dias"
        df = df[df['codsalon'].astype(str) == str(codsalon)]

        if df.empty:
            return JSONResponse(status_code=404, content={"error": f"No hay datos para el sal√≥n {codsalon}"})

        # Convertir fechas a string por compatibilidad JSON
        if "fecha" in df.columns:
            df["fecha"] = df["fecha"].astype(str)

        return df.to_dict(orient="records")
    except Exception as e:
        logger.exception("‚ùå Error al cargar datos KPIs 30 d√≠as")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.post("/chat")
async def chat_handler(request: Request):
    data = await request.json()
    logger.debug(f"‚û°Ô∏è  /chat payload recibido: {data!r}")

    mensaje_usuario = data.get("mensaje")
    codsalon        = data.get("codsalon")
    fecha           = data.get("fecha")

    if not mensaje_usuario or not codsalon or not fecha:
        logger.warning("Faltan campos en la petici√≥n")
        raise HTTPException(
            400,
            "Faltan campos en la petici√≥n. Env√≠ame 'mensaje', 'codsalon' y 'fecha'."
        )

    # Construir prompt forzado
    prompt_user = f"[codsalon={codsalon}]\n[fecha={fecha}]\n{mensaje_usuario}"
    logger.debug(f"üìù prompt_user:\n{prompt_user}")

    system_prompt = (
        "Act√∫a como Mont Direcci√≥n...\n"
        "Si el usuario pregunta por un KPI en d√≠a concreto, invoca explicar_ratio_diario..."
    )

    logger.debug("üîÑ Llamando a OpenAI.chat.completions.create (primera pasada)")
    res = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user",   "content": prompt_user}
        ],
        functions=function_schema,
        function_call="auto"
    )
    logger.debug(f"‚úÖ Respuesta OpenAI primera pasada: {res.choices[0].message!r}")

    msg = res.choices[0].message

    if msg.function_call:
        nombre = msg.function_call.name
        args   = json.loads(msg.function_call.arguments)
        logger.info(f"üîß Modelo invoc√≥ funci√≥n {nombre} con args {args}")

        try:
            resultado_fn = globals()[nombre](**args)
            logger.debug(f"‚úÖ Resultado funci√≥n {nombre}: {resultado_fn!r}")
        except Exception as e:
            logger.exception("‚ùå Error al ejecutar la funci√≥n")
            resultado_fn = f"‚ö†Ô∏è Error interno al ejecutar la funci√≥n: {e}"

        logger.debug("üîÑ Llamando a OpenAI.chat.completions.create (segunda pasada)")
        follow = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system",   "content": system_prompt},
                {"role": "user",     "content": prompt_user},
                {"role": "function", "name": nombre, "content": resultado_fn}
            ]
        )
        respuesta = follow.choices[0].message.content
        logger.debug(f"‚úÖ Respuesta final GPT con funci√≥n: {respuesta!r}")
        return {"respuesta": respuesta}

    # Fallback: invocar directamente
    logger.warning("‚ö†Ô∏è GPT no invoc√≥ la funci√≥n, uso fallback directo")
    resultado_directo = explicar_ratio_diario(codsalon, fecha)
    respuesta = f"¬°Hola! Soy Mont Direcci√≥n.\n\n{resultado_directo}"
    logger.debug(f"‚úÖ Respuesta fallback directo: {respuesta!r}")
    return {"respuesta": respuesta}

